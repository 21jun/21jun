
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2F21jun&count_bg=%23364AB2&title_bg=%23272727&icon=github.svg&icon_color=%23FFFFFF&title=hits&edge_flat=true)](https://hits.seeyoufarm.com)
<!--
**21jun/21jun** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
# Wonjun Lee ğŸŒŠ


## Currently â™»ï¸

Ph.D./MS Student @POSTECH <a href="https://nlp.postech.ac.kr">NLP LAB</a>


### Research interests ğŸ¯

Automatic Speech Recogntion (ASR), Multilingual ASR, MLops, Kubernetes

## Education ğŸ“


`2021.Feb - now`
__POSTECH, Pohang (Korea)__
Ph.D./M.S. Degree (Computer Science and Engineering)


`2017 - 2021`
__Sejong University, Seoul (Korea)__
B.S. Degree (Software Engineering & Data Science)




## Awards ğŸ†

- Best Paper Nominee in SiGDial 2024: Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning
  Wonjun Lee*, San Kim* and Gary Geunbae Lee [<a href="https://2024.sigdial.org/award/">link</a>]


í•œêµ­ì–´ ì¸ê³µì§€ëŠ¥ ê²½ì§„ëŒ€íšŒ (ìŒì„±ì¸ì‹)

- Korean Artificial Intelligence Contest (Speech Recognition) Grand Prize (2nd), Minister's Award, ***Ministry of Science and ICT***, Republic of Korea [<a href="https://youtu.be/yVD7zkpwxDo">link</a>]  [<a href="https://www.aitimes.kr/news/articleView.html?idxno=26202">link</a>], ìµœìš°ìˆ˜ìƒ, ê³¼ê¸°ì •í†µë¶€ ì¥ê´€ìƒ, 2022

- Korean Artificial Intelligence Contest (Speech Recognition) 5th Ranked, Director's Award, *National Information Society Agency (NIA)*, Republic of Korea
[<a href="https://competition.aihub.or.kr/notice/noticeDetail/101">link</a>], ì¥ë ¤ìƒ, ì§€ëŠ¥ì •ë³´ì›(NIA) ì›ì¥ìƒ, 2023

- Korean Artificial Intelligence Contest (Speech Recognition) 4th Ranked, Director's Award, *National Information Society Agency (NIA)*, Republic of Korea [<a href="https://m.etnews.com/20211216000213?obj=Tzo4OiJzdGRDbGFzcyI6Mjp7czo3OiJyZWZlcmVyIjtOO3M6NzoiZm9yd2FyZCI7czoxMzoid2ViIHRvIG1vYmlsZSI7fQ%3D%3D">link</a>], ì¥ë ¤ìƒ, ì§€ëŠ¥ì •ë³´ì›(NIA) ì›ì¥ìƒ, 2021




## Publications ğŸ“œ

### Conference 

#### International

- __DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition__ [<a href="https://arxiv.org/pdf/2501.19010">link</a>]

  **Wonjun Lee***, Solee Im*, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee

  ğŸ‡ºğŸ‡¸ Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (NAACL), 2025, Albuquerque, New Mexico, USA 


- __Enhancing Dialogue Speech Recognition with Robust Contextual Awareness via Noise Representation Learning__  [<a href="https://aclanthology.org/2024.sigdial-1.30/">link</a>] [<a href="https://2024.sigdial.org/award/">link</a>]

  **Wonjun Lee***, San Kim*, Gary Geunbae Lee
  
  ğŸ‡¯ğŸ‡µ ACL/ISCA Special Interest Group on Discourse and Dialogue (SIGDial), 2024, Kyoto, Japan
  

- __An Investigation Into Explainable Audio Hate Speech Detection__  [<a href="https://aclanthology.org/2024.sigdial-1.45/">link</a>] 

  **Wonjun Lee***, Jinmyeong An*, Yejin Jeon, Jungseul Ok, Yunsu Kim, Gary Geunbae Lee

  ğŸ‡¯ğŸ‡µ ACL/ISCA Special Interest Group on Discourse and Dialogue (SIGDial), 2024, Kyoto, Japan
  
- __Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation Assessment__  [<a href="https://arxiv.org/abs/2406.15723">link</a>]

  Heejin Do, **Wonjun Lee**, Gary Geunbae Lee

  ğŸ‡¬ğŸ‡· INTERSPEECH, 2024, Kos Island, Greece

- __Optimizing Two-Pass Cross-Lingual Transfer Learning: Phoneme Recognition and Phoneme to Grapheme Translation__  [<a href="https://arxiv.org/abs/2312.03312">link</a>]

  **Wonjun Lee**, Yunsu Kim and Gary Geunbae Lee

  ğŸ‡¹ğŸ‡¼ IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), 2023, Taipei, Taiwan


- __Exploring the Viability of Synthetic Audio Data for Audio-Based Dialogue State Tracking__ [<a href="https://arxiv.org/abs/2312.01842">link</a>]

  Jihyun Lee*, Yejin Jeon*, **Wonjun Lee**, Yunsu Kim and Gary Geunbae Lee

  ğŸ‡¹ğŸ‡¼ IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), 2023, Taipei, Taiwan




#### Domestic
- __How to Use Speech Related Digital Biomarkers in Patients With Depressive Disorder__ [<a href="https://e-dhr.org/DOIx.php?id=10.61499/dhr.2024.2.e2">link</a>]

  **Wonjun Lee***, Seungyeon Seo*, Hyun Jeong Kim

  ğŸ‡°ğŸ‡· Digital Health Research (Korean Society of Digital Health)

- __í•œêµ­ì–´ ìëª¨ë‹¨ìœ„ ìŒì„±ì¸ì‹ ê²°ê³¼ í›„ë³´ì •ì„ ìœ„í•œ ì‹ ê²½ë§ ê¸°ë°˜ ìëª¨ ë³‘í•© ë°©ë²•ë¡ __

  ì„ì†”ì´*, **ì´ì›ì¤€***, ì´ê·¼ë°°, ê¹€ìœ¤ìˆ˜
  
  ğŸŠ ì œ35íšŒ í•œê¸€ ë° í•œêµ­ì–´ ì •ë³´ì²˜ë¦¬ í•™ìˆ ëŒ€íšŒë…¼ë¬¸ì§‘ (HCLT), 2023, ì œì£¼, ëŒ€í•œë¯¼êµ­

- __ë‹¤êµ­ì–´ ìŒì„±ì¸ì‹ì„ ìœ„í•œ ì–¸ì–´ë³„ ì¶œë ¥ ê³„ì¸µ êµ¬ì¡° Wav2Vec2.0__

  **ì´ì›ì¤€**, ì´ê·¼ë°°

  ğŸ‡°ğŸ‡· ì œ33íšŒ í•œê¸€ ë° í•œêµ­ì–´ ì •ë³´ì²˜ë¦¬ í•™ìˆ ëŒ€íšŒ ë…¼ë¬¸ì§‘ (HCLT), pp. 414-418, 2021


#### Preprints

- __Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking__ [<a href="https://arxiv.org/abs/2409.06263">link</a>]

  Jihyun Lee, Solee Im, **Wonjun Lee**, Gary Geunbae Lee

  ğŸ“„ Preprint, Arxiv.

## Patents

- __Method and Apparatus for Multilingual Speech Recognition based on Artificial Intelligence Models, U.S. , 17/954,185__

<!-- ### Footer

Last updated: May 2013 -->


